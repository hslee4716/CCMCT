{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from utils.data_util import *\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from glob import glob\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# def dcm_to_train_set(db = \"original_data/archive/MITOS_WSI_CCMCT_ODAEL_train_dcm.sqlite\", source_dir = \"original_data/archive\",\\\r\n",
    "#                          dest_dir = \"datasets/new\", tile_size = 512, cell_size = 40):\r\n",
    "m2det_dcm_to_train_set(tile_size=320)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "1 / 21 066c94c4c161224077a9 : 0 / 47850\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\Users\\User\\Desktop\\CCMCT\\utils\\data_util.py:242: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  local_cells = cells[['x','y','annoid']][cells['x'] > location[0]][cells['y'] > location[1]]\\\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "cells = get_all_cells('datasets/new/labels')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'get_all_cells' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-136144ee4f49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcells\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_all_cells\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datasets/new/labels'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_all_cells' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# dcm to png,label & 이상치 제거\r\n",
    "dcm_to_train_set()\r\n",
    "fix_labels(\"datasets/train/images\", \"datasets/train/labels\")\r\n",
    "\r\n",
    "# def dcm_to_train_set(db = \"datasets/archive/MITOS_WSI_CCMCT_ODAEL_train_dcm.sqlite\", source_dir = \"datasets/archive\",\\\r\n",
    "#                          dest_dir = \"datasets/train\", tile_size = 1000, cell_size = 40):"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# train / valid split\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "files = glob(\"datasets/train/labels/*.txt\")\r\n",
    "file_lists = []\r\n",
    "for file_name in files:\r\n",
    "    file_lists.append(file_name.split(\"\\\\\")[1].split(\".\")[0])\r\n",
    "\r\n",
    "train_files, test_files = train_test_split(file_lists, random_state=7, test_size=0.2)\r\n",
    "print(len(train_files), len(test_files))\r\n",
    "\r\n",
    "with open(\"datasets/train/train.txt\", 'w') as f:\r\n",
    "    for train_file in train_files:\r\n",
    "        f.write(train_file+\"\\n\")\r\n",
    "\r\n",
    "with open(\"datasets/train/val.txt\", 'w') as f:\r\n",
    "    for test_file in test_files:\r\n",
    "        f.write(test_file+\"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "33438 8360\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train test split 칸에서 작성된 txt파일에 따라 이미지, 라벨 다른 폴더로 분할\r\n",
    "import shutil\r\n",
    "\r\n",
    "source_dir = \"datasets/new\"\r\n",
    "\r\n",
    "img_dest = \"datasets/Normal/images\"\r\n",
    "label_dest = \"datasets/Normal/labels\"\r\n",
    "\r\n",
    "if not os.path.exists(img_dest):\r\n",
    "    os.makedirs(img_dest)\r\n",
    "    os.makedirs(img_dest + \"/train\")\r\n",
    "    os.makedirs(img_dest + \"/val\")\r\n",
    "\r\n",
    "if not os.path.exists(label_dest):\r\n",
    "    os.makedirs(label_dest)\r\n",
    "    os.makedirs(label_dest + \"/train\")\r\n",
    "    os.makedirs(label_dest + \"/val\")\r\n",
    "\r\n",
    "train_txt = \"datasets/train.txt\"\r\n",
    "val_txt = \"datasets/val.txt\"\r\n",
    "\r\n",
    "with open(train_txt, 'r') as f:\r\n",
    "    train_files = f.readlines()\r\n",
    "\r\n",
    "with open(val_txt, 'r') as f:\r\n",
    "    val_files = f.readlines()    \r\n",
    "\r\n",
    "for train_file in train_files:\r\n",
    "    temp = train_file.strip()\r\n",
    "    shutil.move(source_dir + \"/images/\"+temp+\".png\", img_dest + \"/train\")\r\n",
    "    shutil.move(source_dir + \"/labels/\"+temp+\".txt\", label_dest + \"/train\")\r\n",
    "\r\n",
    "for val_file in val_files:\r\n",
    "    temp = val_file.strip()\r\n",
    "    shutil.move(source_dir + \"/images/\"+temp+\".png\", img_dest + \"/val\")\r\n",
    "    shutil.move(source_dir + \"/labels/\"+temp+\".txt\", label_dest + \"/val\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "cells = get_all_cells(\"datasets/new/labels\")\r\n",
    "cells['label'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3    39515\n",
       "4    36563\n",
       "1    30851\n",
       "2    19621\n",
       "0    12569\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds = ReadableDicomDataset('datasets/archive/fff27b79894fe0157b08.dcm')\r\n",
    "# location=(69700,17100)\r\n",
    "# size=(500,500)\r\n",
    "\r\n",
    "location=(60000,40000)\r\n",
    "size=(3000,3000)\r\n",
    "img = Image.fromarray(ds.read_region(location=location,size=size))\r\n",
    "img"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get the annotation coordinates, offset by the left upper coordinate (location)\r\n",
    "# NOTE: We would actually have to check the label class - which we omit for the sake of simplicity here\r\n",
    "DB = sqlite3.connect('datasets/archive/MITOS_WSI_CCMCT_ODAEL_train_dcm.sqlite')\r\n",
    "cur = DB.cursor()\r\n",
    "\r\n",
    "cells = cur.execute(f\"\"\"SELECT coordinateX-{location[0]}, coordinateY-{location[1]}\r\n",
    "                        from Annotations_coordinates where slide==7 and \r\n",
    "                        coordinateX>{location[0]} and coordinateX<{location[0]+size[0]} and \r\n",
    "                        coordinateY>{location[1]} and coordinateY<{location[1]+size[1]}\"\"\").fetchall()\r\n",
    "\r\n",
    "from PIL import ImageDraw\r\n",
    "draw = ImageDraw.Draw(img)\r\n",
    "for (cx,cy) in cells:\r\n",
    "    r=25\r\n",
    "    draw.ellipse([(cx-r,cy-r),(cx+r,cy+r)],outline=(255,0,0,255))\r\n",
    "img"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import os\r\n",
    "with open(\"temp.txt\", 'w+') as f:\r\n",
    "    a=1\r\n",
    "print(os.path.getsize(\"temp.txt\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('ccmct': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "8c2404bd8ca2f9cfec9a23a8cacc0264d0bce9fde456fc45053c7531705909fc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}